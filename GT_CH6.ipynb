{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GT_CH6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNqo17Wa2R+Tcif2T3/Tpn5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/James606240/NTUT_Test/blob/main/GT_CH6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJpWGX1JeFLW"
      },
      "source": [
        "# P.206\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import initializers"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2U_298IVsxW2"
      },
      "source": [
        "# P.206\n",
        "def parse_aug_fn(dataset):\n",
        "    \"\"\"\n",
        "    Image Augmentation(影像增強) function\n",
        "    \"\"\"\n",
        "    x = tf.cast(dataset['image'], tf.float32) / 255.  # 影像標準化\n",
        "    x = flip(x)  # 隨機水平翻轉\n",
        "    # 觸發顏色轉換機率50%\n",
        "    x = tf.cond(tf.random.uniform([], 0, 1) > 0.5, lambda: color(x), lambda: x)\n",
        "    # 觸發影像旋轉機率0.25%\n",
        "    x = tf.cond(tf.random.uniform([], 0, 1) > 0.75, lambda: rotate(x), lambda: x)\n",
        "    # 觸發影像縮放機率50%\n",
        "    x = tf.cond(tf.random.uniform([], 0, 1) > 0.5, lambda: zoom(x), lambda: x)\n",
        "    # 將輸出標籤轉乘One-hot編碼\n",
        "    y = tf.one_hot(dataset['label'], 10)\n",
        "    return x, y\n",
        "\n",
        "\n",
        "def parse_fn(dataset):\n",
        "    x = tf.cast(dataset['image'], tf.float32) / 255.  # 影像標準化\n",
        "    # 將輸出標籤轉乘One-hot編碼\n",
        "    y = tf.one_hot(dataset['label'], 10)\n",
        "    return x, y\n",
        "\n",
        "\n",
        "def flip(x):\n",
        "    \"\"\"\n",
        "    flip image(翻轉影像)\n",
        "    \"\"\"\n",
        "    x = tf.image.random_flip_left_right(x)  # 隨機左右翻轉影像\n",
        "    return x\n",
        "\n",
        "\n",
        "def color(x):\n",
        "    \"\"\"\n",
        "     Color change(改變顏色)\n",
        "    \"\"\"\n",
        "    x = tf.image.random_hue(x, 0.08)  # 隨機調整影像色調\n",
        "    x = tf.image.random_saturation(x, 0.6, 1.6)  # 隨機調整影像飽和度\n",
        "    x = tf.image.random_brightness(x, 0.05)  # 隨機調整影像亮度\n",
        "    x = tf.image.random_contrast(x, 0.7, 1.3)  # 隨機調整影像對比度\n",
        "    return x\n",
        "\n",
        "\n",
        "def rotate(x):\n",
        "    \"\"\"\n",
        "    Rotation image(影像旋轉)\n",
        "    \"\"\"\n",
        "    # 隨機選轉n次(通過minval和maxval設定n的範圍)，每次選轉90度\n",
        "    x = tf.image.rot90(x,tf.random.uniform(shape=[],minval=1,maxval=4,dtype=tf.int32))\n",
        "    return x\n",
        "\n",
        "\n",
        "def zoom(x, scale_min=0.6, scale_max=1.4):\n",
        "    \"\"\"\n",
        "    Zoom Image(影像縮放)\n",
        "    \"\"\"\n",
        "    h, w, c = x.shape\n",
        "    scale = tf.random.uniform([], scale_min, scale_max)  # 隨機縮放比例\n",
        "    sh = h * scale  # 縮放後影像長度\n",
        "    sw = w * scale  # 縮放後影像寬度\n",
        "    x = tf.image.resize(x, (sh, sw))  # 影像縮放\n",
        "    x = tf.image.resize_with_crop_or_pad(x, h, w)  # 影像裁減和填補\n",
        "    return x"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keS_mimkeRDe"
      },
      "source": [
        "# P.206\n",
        "# 載入Cifar10數據集\n",
        "# 將train Data重新分成9:1等分，分別分給train data, valid data\n",
        "train_split, valid_split = ['train[:90%]', 'train[90%:]']\n",
        "# 取得訓練數據，並順便讀取data的資訊\n",
        "train_data, info = tfds.load(\"cifar10\", split=train_split, with_info=True)\n",
        "# 取得驗證數據\n",
        "valid_data = tfds.load(\"cifar10\", split=valid_split)\n",
        "# 取得測試數據\n",
        "test_data = tfds.load(\"cifar10\", split=tfds.Split.TEST)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHMZUGQ9eqab"
      },
      "source": [
        "# P.206\n",
        "# Dataset 設定\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE  # 自動調整模式\n",
        "batch_size = 64  # 批次大小\n",
        "train_num = int(info.splits['train'].num_examples / 10) * 9  # 訓練資料數量\n",
        "\n",
        "train_data = train_data.shuffle(train_num)  # 打散資料集\n",
        "# 載入預處理「 parse_aug_fn」function，cpu數量為自動調整模式\n",
        "train_data = train_data.map(map_func=parse_aug_fn, num_parallel_calls=AUTOTUNE)\n",
        "# 設定批次大小並將prefetch模式開啟(暫存空間為自動調整模式)\n",
        "train_data = train_data.batch(batch_size).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "# 載入預處理「 parse_fn」function，cpu數量為自動調整模式\n",
        "valid_data = valid_data.map(map_func=parse_fn, num_parallel_calls=AUTOTUNE)\n",
        "# 設定批次大小並將prefetch模式開啟(暫存空間為自動調整模式)\n",
        "valid_data = valid_data.batch(batch_size).prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "# 載入預處理「 parse_fn」function，cpu數量為自動調整模式\n",
        "test_data = test_data.map(map_func=parse_fn, num_parallel_calls=AUTOTUNE)\n",
        "# 設定批次大小並將prefetch模式開啟(暫存空間為自動調整模式)\n",
        "test_data = test_data.batch(batch_size).prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOsUS8dBAXMx"
      },
      "source": [
        "**使用客自化API訓練網路模型**\n",
        "# *   Custom Layer：將原本的Conv2d改成CustomConv2D。\n",
        "# *   Custom Loss：將原本的CategoricalCrossentropy改成custom_loss。\n",
        "# *   Custom Metrics：加入一個新的指標函數CatgoricalTruePositives。\n",
        "# *   Custom Callbacks：紀錄每一個batch的Loss值變化。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyaJofj2e2Vf",
        "outputId": "552a4b41-ff6d-4ba8-9a98-09f612f5fe99"
      },
      "source": [
        "# P.207\n",
        "# Custom Layer：將原本的Conv2d改成CustomConv2D。\n",
        "# 1. 使用Keras高階API訓練網路模型\n",
        "inputs = keras.Input(shape=(32, 32, 3))\n",
        "x = layers.Conv2D(64, 3, activation='relu', kernel_initializer='glorot_uniform')(inputs)\n",
        "x = layers.MaxPool2D()(x)\n",
        "x = layers.Conv2D(128, 3, activation='relu', kernel_initializer='glorot_uniform')(x)\n",
        "x = layers.Conv2D(256, 3, activation='relu', kernel_initializer='glorot_uniform')(x)\n",
        "x = layers.Conv2D(128, 3, activation='relu', kernel_initializer='glorot_uniform')(x)\n",
        "x = layers.Conv2D(64, 3, activation='relu', kernel_initializer='glorot_uniform')(x)\n",
        "# https://towardsdatascience.com/hyper-parameters-in-action-part-ii-weight-initializers-35aee1a28404\n",
        "# https://www.pythonheidong.com/blog/article/553510/a0f663ad89fade5ba00e/\n",
        "# https://towardsdatascience.com/hyper-parameters-in-action-a524bf5bf1c\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(10)(x)\n",
        "# 建立網路模型(將輸入到輸出所有經過的網路層連接起來)\n",
        "model_1 = keras.Model(inputs, outputs, name='model-1')\n",
        "model_1.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model-1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 30, 30, 64)        1792      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 13, 13, 128)       73856     \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 11, 11, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 9, 9, 128)         295040    \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 7, 7, 64)          73792     \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                200768    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 941,066\n",
            "Trainable params: 941,066\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MVMpSmeW_EJN"
      },
      "source": [
        "# P.208\n",
        "# Custom Callbacks：紀錄每一個batch的Loss值變化。\n",
        "# 儲存訓練記錄檔\n",
        "logs_dirs = 'lab6-logs'\n",
        "model_cbk = keras.callbacks.TensorBoard('lab6-logs')\n",
        "# 紀錄每一個batch的Loss值變化\n",
        "model_dirs = logs_dirs + '/models'\n",
        "os.makedirs(model_dirs, exist_ok=True)\n",
        "# exist_ok (optional) : A default value False is used for this parameter. If the target directory already exists an OSError is raised if its value is False otherwise not. For value True leaves directory unaltered.\n",
        "custom_save_model = keras.callbacks.ModelCheckpoint(model_dirs + '/custom_save.h5', \n",
        "                              monitor='val_custom_catrgorical_accuracy', \n",
        "                              mode='max', \n",
        "                              save_weights_only=True)\n",
        "# save_weights_only: 如果 True，那麼只有模型的權重會被保存 (model.save_weights(filepath))， 否則的話，整個模型會被保存 (model.save(filepath))。"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ll0c1DRf_FLK",
        "outputId": "54614624-4814-4cbd-8cc4-118f3f47d1da"
      },
      "source": [
        "# P.208\n",
        "# Custom Loss：將原本的CategoricalCrossentropy改成custom_loss。\n",
        "# Custom Metrics：加入一個新的指標函數CatgoricalTruePositives。\n",
        "\n",
        "# 設定訓練使用的優化器、損失函數和指標函數\n",
        "model_1.compile(keras.optimizers.Adam(), \n",
        "           loss=keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "# from_logits=True means the input to crossEntropy layer is normal tensor/logits, while if from_logits=False, means the input is a probability and usually you should have some softmax activation in your last layer. \n",
        "           metrics=[keras.metrics.CategoricalAccuracy()])\n",
        "\n",
        "# 訓練網路模型\n",
        "model_1.fit(train_data,\n",
        "            epochs=1,\n",
        "            # 書上是epochs=100，考量運行速度改為epochs=1\n",
        "            validation_data=valid_data,\n",
        "            callbacks=[model_cbk, custom_save_model])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "704/704 [==============================] - 536s 754ms/step - loss: 2.1623 - categorical_accuracy: 0.1740 - val_loss: 1.8475 - val_categorical_accuracy: 0.3136\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6f3d4a1590>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JnPIXF7_HZy",
        "outputId": "0a045f6f-797a-4e58-8e86-4fb6d5248c61"
      },
      "source": [
        "# P.214\n",
        "model_1.load_weights(model_dirs+'/custom_save.h5')\n",
        "loss, acc = model_1.evaluate(test_data)\n",
        "print(\"Loss: {}, Accuracy: {}\".format(loss, acc))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 29s 186ms/step - loss: 1.8515 - categorical_accuracy: 0.3026\n",
            "Loss: 1.8515105247497559, Accuracy: 0.3025999963283539\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}